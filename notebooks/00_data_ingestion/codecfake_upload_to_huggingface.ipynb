{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2b86ff-b6a1-458c-85bf-92e5faa4cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69bddd9-35ff-4c4c-9064-95e41f6c02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm            import tqdm\n",
    "from getpass         import getpass\n",
    "from datasets        import Dataset, DatasetDict, Audio\n",
    "from huggingface_hub import HfApi, HfFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6317a44b-b2ea-416d-af82-0eb31637cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "138c2d49-00cd-4500-961f-c451282f7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "config    = load_config()\n",
    "audio_dir = config['data_paths']['codecfake']['audio_files']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d63c69-c008-48aa-9d75-a880e0579e68",
   "metadata": {},
   "source": [
    "### Hugging Face Token Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6973936-cce9-455b-8244-370af20194d8",
   "metadata": {},
   "source": [
    "\n",
    "This notebook requires access to the Hugging Face API. You have several options to set up your environment with the necessary token.\n",
    "\n",
    "**Option 1: Using Environment Variables**\n",
    "\n",
    "1.a Setting Environment Variables Directly\n",
    "\n",
    "Set the `HF_TOKEN` environment variable with your Hugging Face token. This can be done in your terminal:\n",
    "\n",
    "**For Windows:**\n",
    "```cmd\n",
    "set HF_TOKEN=your_token_here\n",
    "```\n",
    "\n",
    "**For macOS/Linux:**\n",
    "```bash\n",
    "export HF_TOKEN=your_token_here\n",
    "```\n",
    "\n",
    "1.b Using a `.env` File\n",
    "\n",
    "Create a `.env` file in the root directory of your project and add the following line:\n",
    "```\n",
    "HF_TOKEN=your_token_here\n",
    "```\n",
    "\n",
    "Then, use a library like `python-dotenv` to load the variables from the `.env` file. Install `python-dotenv` if you haven't already:\n",
    "```bash\n",
    "pip install python-dotenv\n",
    "```\n",
    "\n",
    "Add the following code to your script to load the environment variables:\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv('HF_TOKEN')\n",
    "```\n",
    "\n",
    "**Option 2: Using Hugging Face CLI**\n",
    "\n",
    "Run the following command in your terminal to log in using the Hugging Face CLI:\n",
    "```bash\n",
    "huggingface-cli login\n",
    "```\n",
    "\n",
    "**What It Does**\n",
    "\n",
    "The `huggingface-cli login` command will prompt you to enter your Hugging Face credentials (username and password). After logging in, the CLI stores your token in a local file (usually located at `~/.huggingface/token`). This token is then used to authenticate your API requests without needing to re-enter your credentials.\n",
    "\n",
    "**Example Code to Handle Token Setup in the Notebook**\n",
    "\n",
    "Here’s an example of how to handle the Hugging Face token setup in your notebook, incorporating all the methods above:\n",
    "\n",
    "```python\n",
    "import os\n",
    "from huggingface_hub import HfFolder, HfApi\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def get_hf_token():\n",
    "    # Load environment variables from .env file, if it exists\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Check for the token in environment variables\n",
    "    token = os.getenv('HF_TOKEN')\n",
    "    if token is None:\n",
    "        # If not found in environment variables, check the Hugging Face CLI session\n",
    "        token = HfFolder.get_token()\n",
    "    return token\n",
    "\n",
    "# Attempt to retrieve the Hugging Face token\n",
    "token = get_hf_token()\n",
    "\n",
    "# If token is not set, prompt the user to enter it\n",
    "if token is None:\n",
    "    token = input(\"Please enter your Hugging Face token: \")\n",
    "\n",
    "# Initialize Hugging Face API with the token\n",
    "hf_api = HfApi(token)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2dce94-2701-452b-bdb7-0c32e622d8c5",
   "metadata": {},
   "source": [
    "### Uploading CodecFake Audio files to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27b8031-6d91-4d0f-8441-45dd5d50354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to retrieve the Hugging Face token from the environment variable or from the user's Hugging Face CLI session\n",
    "token = HfFolder.get_token()\n",
    "\n",
    "if token is None:\n",
    "    token = getpass(\"Please enter your Hugging Face token: \")\n",
    "\n",
    "# Initialize Hugging Face API with the token\n",
    "hf_api = HfApi(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7162b7f-5bc1-4e86-8697-acf6279666ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  18%|█▊        | 6300/35449 [00:02<00:12, 2263.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SSB00050012\n",
      "Skipping SSB00050012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  27%|██▋       | 9737/35449 [00:04<00:14, 1775.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SSB00050007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  29%|██▊       | 10116/35449 [00:05<00:13, 1830.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SSB00050009\n",
      "Skipping SSB00050009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  33%|███▎      | 11564/35449 [00:06<00:13, 1769.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SSB00050008\n",
      "Skipping SSB00050008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  34%|███▍      | 12144/35449 [00:06<00:12, 1874.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SSB00050006\n",
      "Skipping SSB00050006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  66%|██████▌   | 23241/35449 [00:12<00:06, 1897.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SSB00050011\n",
      "Skipping SSB00050011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  70%|██████▉   | 24739/35449 [00:13<00:05, 1802.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SSB00050010\n",
      "Skipping SSB00050010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  81%|████████  | 28547/35449 [00:15<00:03, 1906.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SSB00050003\n",
      "Skipping SSB00050003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  87%|████████▋ | 30925/35449 [00:16<00:02, 1942.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SSB00050002\n",
      "Skipping SSB00050002\n",
      "Skipping SSB00050002\n",
      "Skipping SSB00050002\n",
      "Skipping SSB00050002\n",
      "Skipping SSB00050002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 35449/35449 [00:19<00:00, 1842.38it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_df(audio_dir):\n",
    "    data = []\n",
    "    \n",
    "    for root, _, files in tqdm(os.walk(audio_dir), total=len(os.listdir(audio_dir)), desc=\"Processing audio files\"):\n",
    "        for file in files:\n",
    "            if file.endswith('.flac'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                audio_id = os.path.basename(os.path.dirname(file_path))\n",
    "\n",
    "                if audio_id.startswith('SSB'):\n",
    "                    print(f'Skipping {audio_id}')\n",
    "                    continue\n",
    "                \n",
    "                if file.startswith('F0'):\n",
    "                    real_or_fake = file[:3]\n",
    "                else:\n",
    "                    real_or_fake = 'R'\n",
    "                data.append({\"audio\": file_path, \"audio_id\": audio_id, \"real_or_fake\": real_or_fake})\n",
    "                \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df = create_df(audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2be619c-e53a-4319-a179-215e6d815ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35433"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of unique audio IDs\n",
    "unique_audio_ids = df['audio_id'].nunique()\n",
    "unique_audio_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2dd770-ee99-41dd-a39f-22d730f7e15d",
   "metadata": {},
   "source": [
    "Since the file is large, we are breaking it into more manageable chunks (of desired chunk size between 90 and 110). \n",
    "\n",
    "To ensure that the file is divided evenly, we are checking for the best common divisor within this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6930b5c-954a-488e-967f-60c2c73938c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 93, Number of Chunks: 381\n"
     ]
    }
   ],
   "source": [
    "desired_chunk_size_min = 90\n",
    "desired_chunk_size_max = 110\n",
    "\n",
    "def find_best_chunk_size(total_ids, min_size, max_size):\n",
    "    for size in range(max_size, min_size - 1, -1):\n",
    "        if total_ids % size == 0:\n",
    "            return size\n",
    "    raise ValueError(\"No suitable chunk size found within the given range.\")\n",
    "\n",
    "try:\n",
    "    chunk_size = find_best_chunk_size(unique_audio_ids, desired_chunk_size_min, desired_chunk_size_max)\n",
    "    num_chunks = unique_audio_ids // chunk_size\n",
    "    print(f\"Chunk Size: {chunk_size}, Number of Chunks: {num_chunks}\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb2c8ee-e711-4ce0-8471-ee8e449d135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating chunks: 100%|██████████| 35433/35433 [00:06<00:00, 5193.88it/s]\n"
     ]
    }
   ],
   "source": [
    "chunk_index      = 0\n",
    "datasets         = []\n",
    "current_chunk    = []\n",
    "audio_ids_so_far = set()\n",
    "\n",
    "# Group the DataFrame by audio_id\n",
    "grouped = df.copy().groupby('audio_id')\n",
    "\n",
    "def read_audio_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return {'bytes': f.read()}\n",
    "\n",
    "def save_chunk(chunk_data, chunk_index):\n",
    "    chunk_name = f\"partition{chunk_index}\"\n",
    "    df_chunk = pd.DataFrame(chunk_data)\n",
    "    ds_chunk = Dataset.from_pandas(df_chunk)\n",
    "    ds_chunk = ds_chunk.cast_column(\"audio\", Audio(decode=True))\n",
    "    datasets.append((chunk_name, ds_chunk))\n",
    "\n",
    "# Iterate over the grouped data and create chunks\n",
    "for audio_id, group in tqdm(grouped, desc=\"Creating chunks\"):\n",
    "    if audio_id in audio_ids_so_far:\n",
    "        continue\n",
    "\n",
    "    if len(audio_ids_so_far) + 1 > chunk_size:\n",
    "        save_chunk(current_chunk, chunk_index)\n",
    "        current_chunk = []\n",
    "        audio_ids_so_far = set()\n",
    "        chunk_index += 1\n",
    "\n",
    "    current_chunk.extend(group.to_dict('records'))\n",
    "    audio_ids_so_far.add(audio_id)\n",
    "\n",
    "# Save the last chunk if it has remaining data\n",
    "if current_chunk:\n",
    "    save_chunk(current_chunk, chunk_index)\n",
    "\n",
    "# Create a DatasetDict from the chunks\n",
    "dataset_dict = DatasetDict({chunk_name: ds for chunk_name, ds in datasets})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b28bdb-6ff5-4a25-8d19-c564bd8182c4",
   "metadata": {},
   "source": [
    "### Push it to HuggingFace Dataset Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f2866a4-0edb-4f1e-b16f-a3848d8ad9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = 'ajaykarthick/codecfake-audio'\n",
    "dataset_dict.push_to_hub(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86f15e-e0ff-447c-865c-828ccc9a1161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418feba-1191-40ce-8a4e-c15ef88fa8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c9673-4ea1-45f7-bb5f-88ccff5545b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9e967-5356-4cef-8b34-2ae3700f45d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c7def-9302-4b41-b028-c01067de3f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d26ad3-2f2f-4d9f-b636-e80d61ed12e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9847ac5-2a0a-4575-b15d-2eceeb8872dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
